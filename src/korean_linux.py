#!/usr/bin/env python3
"""
Korean Linux - í•œêµ­ì–´ë¡œ ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´ ì‹¤í–‰í•˜ê¸°
Google Colab ì „ìš© íŒ¨í‚¤ì§€
"""

import os
import sys
import subprocess
import re
import json

# ì „ì—­ ë³€ìˆ˜
_model = None
_tokenizer = None
_device = None

# ============================================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼)
# ============================================================
SYSTEM_PROMPT = """You are a Linux command assistant. You can use many tools (functions) to help users with their Linux tasks.
At each step, you need to give your thought to analyze the status now and what to do next, with a function call to actually execute your step. Your output should follow this format:
Thought:
Action
Action Input:

After the call, you will get the call result, and you are now in a new state.
Then you will analyze your status now, then decide what to do next...
After many (Thought-call) pairs, you finally perform the task, then you can give your final answer.

Remember:
1. The state change is irreversible, you can't go back to one of the former state.
2. All the thought is short, at most in 5 sentences.
3. ALWAYS call "Finish" function at the end of the task.
4. If you cannot handle the task with the available tools, say you don't know and call Finish with give_answer.

You have access of the following tools:
[
  {"name": "ls_command", "description": "List directory contents.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "options": {"type": "string"}}, "required": ["path"]}},
  {"name": "cd_command", "description": "Change the current working directory.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}}, "required": ["path"]}},
  {"name": "mkdir_command", "description": "Create a new directory.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}}, "required": ["path"]}},
  {"name": "rm_command", "description": "Remove files or directories.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "recursive": {"type": "boolean"}}, "required": ["path"]}},
  {"name": "cp_command", "description": "Copy files or directories.", "parameters": {"type": "object", "properties": {"source": {"type": "string"}, "destination": {"type": "string"}}, "required": ["source", "destination"]}},
  {"name": "mv_command", "description": "Move or rename files.", "parameters": {"type": "object", "properties": {"source": {"type": "string"}, "destination": {"type": "string"}}, "required": ["source", "destination"]}},
  {"name": "find_command", "description": "Find files by name pattern.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "name": {"type": "string"}}, "required": ["path", "name"]}},
  {"name": "cat_command", "description": "Display file contents.", "parameters": {"type": "object", "properties": {"file": {"type": "string"}}, "required": ["file"]}},
  {"name": "grep_command", "description": "Search for patterns in files.", "parameters": {"type": "object", "properties": {"pattern": {"type": "string"}, "file": {"type": "string"}}, "required": ["pattern", "file"]}},
  {"name": "head_command", "description": "Display first lines of a file.", "parameters": {"type": "object", "properties": {"file": {"type": "string"}, "lines": {"type": "integer"}}, "required": ["file"]}},
  {"name": "tail_command", "description": "Display last lines of a file.", "parameters": {"type": "object", "properties": {"file": {"type": "string"}, "lines": {"type": "integer"}}, "required": ["file"]}},
  {"name": "wc_command", "description": "Count lines, words, and bytes.", "parameters": {"type": "object", "properties": {"file": {"type": "string"}}, "required": ["file"]}},
  {"name": "ps_command", "description": "Display running processes.", "parameters": {"type": "object", "properties": {"options": {"type": "string"}}, "required": []}},
  {"name": "df_command", "description": "Display disk space usage.", "parameters": {"type": "object", "properties": {"options": {"type": "string"}}, "required": []}},
  {"name": "du_command", "description": "Display directory space usage.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "options": {"type": "string"}}, "required": ["path"]}},
  {"name": "top_command", "description": "Display system processes in real-time.", "parameters": {"type": "object", "properties": {}, "required": []}},
  {"name": "ping_command", "description": "Test network connectivity.", "parameters": {"type": "object", "properties": {"host": {"type": "string"}, "count": {"type": "integer"}}, "required": ["host"]}},
  {"name": "curl_command", "description": "Transfer data from URL.", "parameters": {"type": "object", "properties": {"url": {"type": "string"}, "options": {"type": "string"}}, "required": ["url"]}},
  {"name": "chmod_command", "description": "Change file permissions.", "parameters": {"type": "object", "properties": {"mode": {"type": "string"}, "file": {"type": "string"}}, "required": ["mode", "file"]}},
  {"name": "tar_command", "description": "Archive or extract files.", "parameters": {"type": "object", "properties": {"options": {"type": "string"}, "archive": {"type": "string"}, "files": {"type": "string"}}, "required": ["options", "archive"]}},
  {"name": "Finish", "description": "Complete the task.", "parameters": {"type": "object", "properties": {"give_answer": {"type": "string"}}, "required": ["give_answer"]}}
]"""


def setup():
    """ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”©"""
    global _model, _tokenizer, _device
    
    if _model is not None:
        return  # ì´ë¯¸ ë¡œë”©ë¨
    
    print("ğŸ”§ Korean Linux ì´ˆê¸°í™” ì¤‘...")
    
    # í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
    try:
        import torch
        import sentencepiece as spm
        from huggingface_hub import hf_hub_download
    except ImportError:
        print("ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...")
        os.system("pip install -q torch sentencepiece huggingface_hub")
        import torch
        import sentencepiece as spm
        from huggingface_hub import hf_hub_download
    
    # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    repo_id = "Yaongi/HybriKo-117M-LinuxFC-SFT-v2"
    files = ["configuration_hybridko.py", "modeling_hybridko.py", 
             "pytorch_model.pt", "HybriKo_tok.model"]
    
    download_dir = "/content/korean_linux_model"
    os.makedirs(download_dir, exist_ok=True)
    
    for f in files:
        if not os.path.exists(os.path.join(download_dir, f)):
            print(f"  ğŸ“¥ {f} ë‹¤ìš´ë¡œë“œ ì¤‘...")
            hf_hub_download(repo_id, f, local_dir=download_dir)
    
    # ëª¨ë¸ ë¡œë”©
    sys.path.insert(0, download_dir)
    from configuration_hybridko import HybriKoConfig
    from modeling_hybridko import HybriKoModel
    
    print("ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘...")
    _tokenizer = spm.SentencePieceProcessor()
    _tokenizer.Load(os.path.join(download_dir, "HybriKo_tok.model"))
    
    config = HybriKoConfig(
        d_model=768, n_layers=12, vocab_size=32000,
        n_heads=12, n_kv_heads=3, ff_mult=3, max_seq_len=6144
    )
    _model = HybriKoModel(config)
    checkpoint = torch.load(
        os.path.join(download_dir, "pytorch_model.pt"),
        map_location="cpu", weights_only=False
    )
    _model.load_state_dict(checkpoint["model_state_dict"])
    
    _device = "cuda" if torch.cuda.is_available() else "cpu"
    _model.to(_device).eval()
    
    print(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ! (Device: {_device})")


def _generate(prompt: str, max_new_tokens: int = 150) -> str:
    """ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ìƒì„±"""
    import torch
    
    input_ids = _tokenizer.EncodeAsIds(prompt)
    input_tensor = torch.tensor([input_ids], dtype=torch.long, device=_device)
    prompt_len = len(input_ids)
    
    with torch.no_grad():
        generated = input_tensor
        for _ in range(max_new_tokens):
            outputs = _model(generated)
            logits = outputs["logits"] if isinstance(outputs, dict) else outputs.logits
            next_token = torch.argmax(logits[:, -1, :], dim=-1, keepdim=True)
            generated = torch.cat([generated, next_token], dim=1)
            
            # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
            new_tokens = generated[0, prompt_len:].tolist()
            new_text = _tokenizer.DecodeIds(new_tokens)
            
            if "<|im_end|>" in new_text:
                break
            
            # Action Input JSON ì™„ë£Œ í™•ì¸
            if "Action Input:" in new_text:
                ai_idx = new_text.find("Action Input:")
                after_ai = new_text[ai_idx + 13:].strip()
                if after_ai.startswith("{"):
                    brace_count = 0
                    for c in after_ai:
                        if c == "{": brace_count += 1
                        elif c == "}": brace_count -= 1
                        if brace_count == 0:
                            return new_text
    
    new_tokens = generated[0, prompt_len:].tolist()
    return _tokenizer.DecodeIds(new_tokens)


def _parse_response(response: str) -> dict:
    """ëª¨ë¸ ì‘ë‹µ íŒŒì‹±"""
    if "<|im_end|>" in response:
        response = response.split("<|im_end|}")[0]
    
    result = {"thought": None, "action": None, "params": None}
    
    # Thought ì¶”ì¶œ
    thought_match = re.search(r"Thought:\s*(.+?)(?=\s*Action:|$)", response, re.DOTALL)
    if thought_match:
        result["thought"] = thought_match.group(1).strip()
    
    # Action ì¶”ì¶œ
    action_match = re.search(r"Action:\s*(\w+)", response)
    if action_match:
        result["action"] = action_match.group(1)
    
    # Action Input ì¶”ì¶œ
    input_match = re.search(r"Action Input:\s*(\{[^}]+\})", response, re.DOTALL)
    if input_match:
        try:
            result["params"] = json.loads(input_match.group(1))
        except:
            result["params"] = {}
    
    return result


def _build_command(action: str, params: dict) -> str:
    """ì•¡ì…˜ê³¼ íŒŒë¼ë¯¸í„°ë¡œ ì‹¤ì œ ëª…ë ¹ì–´ ìƒì„± (ë³´ì • í¬í•¨)"""
    
    # Colab íŠ¹ìˆ˜ ì²˜ë¦¬
    if action == "cd_command":
        return f"__CD__:{params.get('path', '.')}"  # íŠ¹ìˆ˜ ë§ˆì»¤
    
    if action == "top_command":
        return "top -b -n 1"  # interactive ëª¨ë“œ ë¶ˆê°€
    
    if action == "ping_command":
        count = params.get("count", 4)
        host = params.get("host", "")
        return f"ping -c {count} {host}"
    
    if action == "Finish":
        return f"__FINISH__:{params.get('give_answer', '')}"
    
    # ì¼ë°˜ ëª…ë ¹ì–´
    cmd_map = {
        "ls_command": lambda p: f"ls {p.get('options', '-la')} {p.get('path', '.')}",
        "mkdir_command": lambda p: f"mkdir -p {p.get('path', '')}",
        "rm_command": lambda p: f"rm {'-rf' if p.get('recursive') else ''} {p.get('path', '')}",
        "cp_command": lambda p: f"cp {p.get('source', '')} {p.get('destination', '')}",
        "mv_command": lambda p: f"mv {p.get('source', '')} {p.get('destination', '')}",
        "find_command": lambda p: f"find {p.get('path', '.')} -name '{p.get('name', '*')}'",
        "cat_command": lambda p: f"cat {p.get('file', '')}",
        "grep_command": lambda p: f"grep '{p.get('pattern', '')}' {p.get('file', '')}",
        "head_command": lambda p: f"head -n {p.get('lines', 10)} {p.get('file', '')}",
        "tail_command": lambda p: f"tail -n {p.get('lines', 10)} {p.get('file', '')}",
        "wc_command": lambda p: f"wc {p.get('file', '')}",
        "ps_command": lambda p: f"ps {p.get('options', 'aux')}",
        "df_command": lambda p: f"df {p.get('options', '-h')}",
        "du_command": lambda p: f"du {p.get('options', '-sh')} {p.get('path', '.')}",
        "curl_command": lambda p: f"curl {p.get('options', '')} {p.get('url', '')}",
        "chmod_command": lambda p: f"chmod {p.get('mode', '')} {p.get('file', '')}",
        "tar_command": lambda p: f"tar {p.get('options', '')} {p.get('archive', '')} {p.get('files', '')}",
    }
    
    if action in cmd_map:
        return cmd_map[action](params or {})
    
    return None


def _execute_command(cmd: str) -> str:
    """ëª…ë ¹ì–´ ì‹¤í–‰"""
    
    # cd íŠ¹ìˆ˜ ì²˜ë¦¬
    if cmd.startswith("__CD__:"):
        path = cmd[7:]
        try:
            os.chdir(path)
            return f"í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}"
        except Exception as e:
            return f"ì˜¤ë¥˜: {e}"
    
    # Finish ì²˜ë¦¬
    if cmd.startswith("__FINISH__:"):
        return cmd[11:]
    
    # ì¼ë°˜ ëª…ë ¹ì–´ ì‹¤í–‰
    try:
        result = subprocess.run(
            cmd, shell=True, capture_output=True, text=True, timeout=30
        )
        output = result.stdout or result.stderr or "(ì¶œë ¥ ì—†ìŒ)"
        return output.strip()
    except subprocess.TimeoutExpired:
        return "â° ì‹œê°„ ì´ˆê³¼ (30ì´ˆ)"
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}"


def í•œê¸€(query: str, execute: bool = True, confirm_dangerous: bool = True) -> dict:
    """
    í•œêµ­ì–´ë¡œ ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´ ì‹¤í–‰
    
    Args:
        query: í•œêµ­ì–´ ëª…ë ¹ (ì˜ˆ: "í˜„ì¬ í´ë”ì˜ íŒŒì¼ ëª©ë¡ì„ ë³´ì—¬ì¤˜")
        execute: Trueë©´ ëª…ë ¹ì–´ ì‹¤í–‰, Falseë©´ ë³€í™˜ë§Œ
        confirm_dangerous: Trueë©´ ìœ„í—˜ ëª…ë ¹ì–´ í™•ì¸ ìš”ì²­
    
    Returns:
        dict: {"command": str, "result": str, "action": str, "thought": str}
    """
    # ì´ˆê¸°í™” í™•ì¸
    if _model is None:
        setup()
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = f"<|im_start|>system\n{SYSTEM_PROMPT}<|im_end|>\n<|im_start|>user\n{query}<|im_end|>\n<|im_start|>assistant\n"
    
    # ìƒì„± ë° íŒŒì‹±
    response = _generate(prompt)
    parsed = _parse_response(response)
    
    # ëª…ë ¹ì–´ ìƒì„±
    cmd = _build_command(parsed["action"], parsed["params"])
    
    result_dict = {
        "command": cmd,
        "result": None,
        "action": parsed["action"],
        "thought": parsed["thought"],
        "params": parsed["params"]
    }
    
    # ì¶œë ¥
    print(f"\nğŸ—£ï¸ ì…ë ¥: {query}")
    if parsed["thought"]:
        print(f"ğŸ’­ ìƒê°: {parsed['thought']}")
    print(f"ğŸ”§ ì•¡ì…˜: {parsed['action']}")
    if cmd and not cmd.startswith("__"):
        print(f"ğŸ¤– ëª…ë ¹ì–´: {cmd}")
    
    # ìœ„í—˜ ëª…ë ¹ì–´ í™•ì¸
    if confirm_dangerous and parsed["action"] == "rm_command":
        if parsed["params"] and parsed["params"].get("recursive"):
            print("âš ï¸  ê²½ê³ : ì¬ê·€ ì‚­ì œ ëª…ë ¹ì…ë‹ˆë‹¤!")
            confirm = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if confirm.lower() != 'y':
                result_dict["result"] = "ì‚¬ìš©ìê°€ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤."
                print(f"ğŸ“ ê²°ê³¼: {result_dict['result']}")
                return result_dict
    
    # ì‹¤í–‰
    if execute and cmd:
        result_dict["result"] = _execute_command(cmd)
        print(f"ğŸ“ ê²°ê³¼:\n{result_dict['result']}")
    
    print()
    return result_dict


# ë³„ì¹­
linux = í•œê¸€
ã…ã„± = í•œê¸€


if __name__ == "__main__":
    setup()
    print("\n" + "="*50)
    print("Korean Linux ì¤€ë¹„ ì™„ë£Œ!")
    print("ì‚¬ìš©ë²•: í•œê¸€('íŒŒì¼ ëª©ë¡ ë³´ì—¬ì¤˜')")
    print("="*50 + "\n")
